{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500) \n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_file(filemame):\n",
    "    df = pd.read_csv(filemame, header=None)\n",
    "    df.columns = [\"Exam1Score\", \"Exam2Score\", \"AdmitORNot\"]\n",
    "    return df\n",
    "\n",
    "def segregate_x_y(df):\n",
    "    df_x = df[[\"Exam1Score\", \"Exam2Score\"]]  # single [] gives error in this case\n",
    "    df_y = df[[\"AdmitORNot\"]]  # if i put single [] then it return series and [[]] return dataframe\n",
    "    return df_x, df_y\n",
    "\n",
    "def segregate_x_into_pass_fail(df_x, df_y):\n",
    "    mask_pass = df_y[\"AdmitORNot\"] == 1\n",
    "    df_x_pass = df_x[mask_pass]\n",
    "    df_x_fail = df_x[~mask_pass]\n",
    "    return df_x_pass, df_x_fail\n",
    "\n",
    "def plot_pass_fail(df_x_pass, df_x_fail):\n",
    "    plt.scatter(df_x_pass[\"Exam1Score\"], df_x_pass[\"Exam2Score\"], marker=\"o\", color=\"green\", label=\"Admitted\")\n",
    "    plt.scatter(df_x_fail[\"Exam1Score\"], df_x_fail[\"Exam2Score\"], marker=\"o\", color=\"red\", label=\"Not Admitted\")\n",
    "    plt.xlabel(\"Exam1 Score\")\n",
    "    plt.ylabel(\"Exam2 Score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def fit_x(df_x, df_y):\n",
    "    x = np.c_[np.ones(df_x.shape[0]), df_x] # this will change you data frame to numpy array\n",
    "    theta = np.zeros((x.shape[1], 1))\n",
    "    y = df_y.to_numpy()                     # here are are manually using function to convert dataframe to numpy array\n",
    "    return x, y, theta\n",
    "\n",
    "def z(x, theta):\n",
    "    return np.dot(x, theta)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))  # note outer brackets in denominator are important else it bad/wrong result.\n",
    "\n",
    "def cost_function(theta, x, y):\n",
    "    m = x.shape[0]\n",
    "    h = sigmoid(z(x, theta))\n",
    "    j = (1 / m) * (np.dot(np.log(h).T, -y) - np.dot(np.log(1 - h).T, (1 - y)))\n",
    "    return j\n",
    "\n",
    "def first_deri_j(theta, x, y):\n",
    "    m = x.shape[0]\n",
    "    h = sigmoid(z(x, theta))\n",
    "    calculation = (1 / m) * (np.dot((h - y).T, x))\n",
    "    return calculation.T\n",
    "\n",
    "def get_best_theta_using_scipy_lib(cost_func_name, theta, first_deri_of_cost_func, x, y):\n",
    "    temp = opt.fmin_tnc(func=cost_func_name,\n",
    "                        x0=theta.flatten(),\n",
    "                        fprime=first_deri_of_cost_func,\n",
    "                        args=(x, y.flatten()))\n",
    "    return temp\n",
    "\n",
    "def accuracy(predicted_y, df_y):\n",
    "    diff = predicted_y - df_y\n",
    "    return (float(np.count_nonzero(diff)) / len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_data_file(\"ex2data1.txt\")\n",
    "df_x, df_y = segregate_x_y(df)\n",
    "df_x_pass, df_x_fail = segregate_x_into_pass_fail(df_x, df_y)\n",
    "plt = plot_pass_fail(df_x_pass, df_x_fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_cost using  zero as intial theta= [[0.69314718]]\n",
      "Auto Optimized theta =  [[-25.16131854]\n",
      " [  0.20623159]\n",
      " [  0.20147149]]\n",
      "final_cost using  optimized theta= [[0.2034977]]\n"
     ]
    }
   ],
   "source": [
    "x, y, theta = fit_x(df_x, df_y)\n",
    "initial_cost = cost_function(theta, x, y)\n",
    "print(\"initial_cost using  zero as intial theta=\", initial_cost)\n",
    "theta_optimized = get_best_theta_using_scipy_lib(cost_function, theta, first_deri_j, x, y)\n",
    "theta = np.array([theta_optimized[0][0],theta_optimized[0][1],theta_optimized[0][2]]).reshape(3,1)\n",
    "print(\"Auto Optimized theta = \",theta )\n",
    "print(\"final_cost using  optimized theta=\", cost_function(theta, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exam1Score</th>\n",
       "      <th>Exam2Score</th>\n",
       "      <th>AdmitORNot</th>\n",
       "      <th>probability</th>\n",
       "      <th>ZeroOROne</th>\n",
       "      <th>GoodorBadPrediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.623660</td>\n",
       "      <td>78.024693</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.286711</td>\n",
       "      <td>43.894998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.847409</td>\n",
       "      <td>72.902198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.182599</td>\n",
       "      <td>86.308552</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.032736</td>\n",
       "      <td>75.344376</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45.083277</td>\n",
       "      <td>56.316372</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61.106665</td>\n",
       "      <td>96.511426</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75.024746</td>\n",
       "      <td>46.554014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.423227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bad-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76.098787</td>\n",
       "      <td>87.420570</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84.432820</td>\n",
       "      <td>43.533393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.735388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>95.861555</td>\n",
       "      <td>38.225278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bad-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>75.013658</td>\n",
       "      <td>30.603263</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>82.307053</td>\n",
       "      <td>76.481963</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>69.364589</td>\n",
       "      <td>97.718692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39.538339</td>\n",
       "      <td>76.036811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.156037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53.971052</td>\n",
       "      <td>89.207350</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>69.070144</td>\n",
       "      <td>52.740470</td>\n",
       "      <td>1</td>\n",
       "      <td>0.427717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bad-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>67.946855</td>\n",
       "      <td>46.678574</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>70.661510</td>\n",
       "      <td>92.927138</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>76.978784</td>\n",
       "      <td>47.575964</td>\n",
       "      <td>1</td>\n",
       "      <td>0.574281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>67.372028</td>\n",
       "      <td>42.838438</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>89.676776</td>\n",
       "      <td>65.799366</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50.534788</td>\n",
       "      <td>48.855812</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34.212061</td>\n",
       "      <td>44.209529</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77.924091</td>\n",
       "      <td>68.972360</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>62.271014</td>\n",
       "      <td>69.954458</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>80.190181</td>\n",
       "      <td>44.821629</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600299</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>93.114389</td>\n",
       "      <td>38.800670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.865185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bad-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>61.830206</td>\n",
       "      <td>50.256108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>38.785804</td>\n",
       "      <td>64.995681</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61.379289</td>\n",
       "      <td>72.807887</td>\n",
       "      <td>1</td>\n",
       "      <td>0.897131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>85.404519</td>\n",
       "      <td>57.051984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>52.107980</td>\n",
       "      <td>63.127624</td>\n",
       "      <td>0</td>\n",
       "      <td>0.154911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>52.045405</td>\n",
       "      <td>69.432860</td>\n",
       "      <td>1</td>\n",
       "      <td>0.391939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bad-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>40.236894</td>\n",
       "      <td>71.167748</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>54.635106</td>\n",
       "      <td>52.213886</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>33.915500</td>\n",
       "      <td>98.869436</td>\n",
       "      <td>0</td>\n",
       "      <td>0.852268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bad-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>64.176989</td>\n",
       "      <td>80.908061</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987564</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>74.789253</td>\n",
       "      <td>41.573415</td>\n",
       "      <td>0</td>\n",
       "      <td>0.203988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>34.183640</td>\n",
       "      <td>75.237720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>83.902394</td>\n",
       "      <td>56.308046</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>51.547720</td>\n",
       "      <td>46.856290</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>94.443368</td>\n",
       "      <td>65.568922</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>82.368754</td>\n",
       "      <td>40.618255</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bad-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>51.047752</td>\n",
       "      <td>45.822701</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>62.222676</td>\n",
       "      <td>52.060992</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>77.193035</td>\n",
       "      <td>70.458200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>97.771599</td>\n",
       "      <td>86.727822</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>62.073064</td>\n",
       "      <td>96.768824</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>91.564974</td>\n",
       "      <td>88.696293</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>79.944818</td>\n",
       "      <td>74.163119</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>99.272527</td>\n",
       "      <td>60.999031</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>90.546714</td>\n",
       "      <td>43.390602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.905016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>34.524514</td>\n",
       "      <td>60.396342</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>50.286496</td>\n",
       "      <td>49.804539</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>49.586677</td>\n",
       "      <td>59.808951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>97.645634</td>\n",
       "      <td>68.861573</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>32.577200</td>\n",
       "      <td>95.598548</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bad-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>74.248691</td>\n",
       "      <td>69.824571</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>71.796462</td>\n",
       "      <td>78.453562</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>75.395611</td>\n",
       "      <td>85.759937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>35.286113</td>\n",
       "      <td>47.020514</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>56.253817</td>\n",
       "      <td>39.261473</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>30.058822</td>\n",
       "      <td>49.592974</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>44.668262</td>\n",
       "      <td>66.450086</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66.560894</td>\n",
       "      <td>41.092098</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>40.457551</td>\n",
       "      <td>97.535185</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>49.072563</td>\n",
       "      <td>51.883212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>80.279574</td>\n",
       "      <td>92.116061</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>66.746719</td>\n",
       "      <td>60.991394</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>32.722833</td>\n",
       "      <td>43.307173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>64.039320</td>\n",
       "      <td>78.031688</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977396</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72.346494</td>\n",
       "      <td>96.227593</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>60.457886</td>\n",
       "      <td>73.094998</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>58.840956</td>\n",
       "      <td>75.858448</td>\n",
       "      <td>1</td>\n",
       "      <td>0.905241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>99.827858</td>\n",
       "      <td>72.369252</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>47.264269</td>\n",
       "      <td>88.475865</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917695</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>50.458160</td>\n",
       "      <td>75.809860</td>\n",
       "      <td>1</td>\n",
       "      <td>0.626744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>60.455556</td>\n",
       "      <td>42.508409</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>82.226662</td>\n",
       "      <td>42.719879</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bad-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>88.913896</td>\n",
       "      <td>69.803789</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>94.834507</td>\n",
       "      <td>45.694307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>67.319257</td>\n",
       "      <td>66.589353</td>\n",
       "      <td>1</td>\n",
       "      <td>0.894532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>57.238706</td>\n",
       "      <td>59.514282</td>\n",
       "      <td>1</td>\n",
       "      <td>0.203193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bad-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>80.366756</td>\n",
       "      <td>90.960148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>68.468522</td>\n",
       "      <td>85.594307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997982</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>42.075455</td>\n",
       "      <td>78.844786</td>\n",
       "      <td>0</td>\n",
       "      <td>0.354560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>75.477702</td>\n",
       "      <td>90.424539</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>78.635424</td>\n",
       "      <td>96.647427</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>52.348004</td>\n",
       "      <td>60.769505</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>94.094331</td>\n",
       "      <td>77.159105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>90.448551</td>\n",
       "      <td>87.508792</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>55.482161</td>\n",
       "      <td>35.570703</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>74.492692</td>\n",
       "      <td>84.845137</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>89.845807</td>\n",
       "      <td>45.358284</td>\n",
       "      <td>1</td>\n",
       "      <td>0.924570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>83.489163</td>\n",
       "      <td>48.380286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.858639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>42.261701</td>\n",
       "      <td>87.103851</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>99.315009</td>\n",
       "      <td>68.775409</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>55.340018</td>\n",
       "      <td>64.931938</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bad-prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>74.775893</td>\n",
       "      <td>89.529813</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good-prediction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Exam1Score  Exam2Score  AdmitORNot  probability  ZeroOROne  \\\n",
       "0    34.623660   78.024693           0     0.091034        0.0   \n",
       "1    30.286711   43.894998           0     0.000042        0.0   \n",
       "2    35.847409   72.902198           0     0.043909        0.0   \n",
       "3    60.182599   86.308552           1     0.990425        1.0   \n",
       "4    79.032736   75.344376           1     0.998199        1.0   \n",
       "5    45.083277   56.316372           0     0.010798        0.0   \n",
       "6    61.106665   96.511426           1     0.998978        1.0   \n",
       "7    75.024746   46.554014           1     0.423227        0.0   \n",
       "8    76.098787   87.420570           1     0.999710        1.0   \n",
       "9    84.432820   43.533393           1     0.735388        1.0   \n",
       "10   95.861555   38.225278           0     0.909674        1.0   \n",
       "11   75.013658   30.603263           0     0.028597        0.0   \n",
       "12   82.307053   76.481963           1     0.999270        1.0   \n",
       "13   69.364589   97.718692           1     0.999854        1.0   \n",
       "14   39.538339   76.036811           0     0.156037        0.0   \n",
       "15   53.971052   89.207350           1     0.980959        1.0   \n",
       "16   69.070144   52.740470           1     0.427717        0.0   \n",
       "17   67.946855   46.678574           0     0.148789        0.0   \n",
       "18   70.661510   92.927138           1     0.999707        1.0   \n",
       "19   76.978784   47.575964           1     0.574281        1.0   \n",
       "20   67.372028   42.838438           0     0.066835        0.0   \n",
       "21   89.676776   65.799366           1     0.998627        1.0   \n",
       "22   50.534788   48.855812           0     0.007418        0.0   \n",
       "23   34.212061   44.209529           0     0.000101        0.0   \n",
       "24   77.924091   68.972360           1     0.991878        1.0   \n",
       "25   62.271014   69.954458           1     0.855049        1.0   \n",
       "26   80.190181   44.821629           1     0.600299        1.0   \n",
       "27   93.114389   38.800670           0     0.865185        1.0   \n",
       "28   61.830206   50.256108           0     0.092389        0.0   \n",
       "29   38.785804   64.995681           0     0.016829        0.0   \n",
       "30   61.379289   72.807887           1     0.897131        1.0   \n",
       "31   85.404519   57.051984           1     0.981037        1.0   \n",
       "32   52.107980   63.127624           0     0.154911        0.0   \n",
       "33   52.045405   69.432860           1     0.391939        0.0   \n",
       "34   40.236894   71.167748           0     0.074129        0.0   \n",
       "35   54.635106   52.213886           0     0.033111        0.0   \n",
       "36   33.915500   98.869436           0     0.852268        1.0   \n",
       "37   64.176989   80.908061           1     0.987564        1.0   \n",
       "38   74.789253   41.573415           0     0.203988        0.0   \n",
       "39   34.183640   75.237720           0     0.049580        0.0   \n",
       "40   83.902394   56.308046           1     0.970300        1.0   \n",
       "41   51.547720   46.856290           0     0.006118        0.0   \n",
       "42   94.443368   65.568922           1     0.999461        1.0   \n",
       "43   82.368754   40.618255           0     0.502285        1.0   \n",
       "44   51.047752   45.822701           0     0.004489        0.0   \n",
       "45   62.222676   52.060992           0     0.137024        0.0   \n",
       "46   77.193035   70.458200           1     0.992992        1.0   \n",
       "47   97.771599   86.727822           1     0.999996        1.0   \n",
       "48   62.073064   96.768824           1     0.999205        1.0   \n",
       "49   91.564974   88.696293           1     0.999991        1.0   \n",
       "50   79.944818   74.163119           1     0.998107        1.0   \n",
       "51   99.272527   60.999031           1     0.999500        1.0   \n",
       "52   90.546714   43.390602           1     0.905016        1.0   \n",
       "53   34.524514   60.396342           0     0.002806        0.0   \n",
       "54   50.286496   49.804539           0     0.008523        0.0   \n",
       "55   49.586677   59.808951           0     0.052891        0.0   \n",
       "56   97.645634   68.861573           1     0.999857        1.0   \n",
       "57   32.577200   95.598548           0     0.693708        1.0   \n",
       "58   74.248691   69.824571           1     0.985497        1.0   \n",
       "59   71.796462   78.453562           1     0.995729        1.0   \n",
       "60   75.395611   85.759937           1     0.999532        1.0   \n",
       "61   35.286113   47.020514           0     0.000222        0.0   \n",
       "62   56.253817   39.261473           0     0.003505        0.0   \n",
       "63   30.058822   49.592974           0     0.000127        0.0   \n",
       "64   44.668262   66.450086           0     0.071657        0.0   \n",
       "65   66.560894   41.092098           0     0.040876        0.0   \n",
       "66   40.457551   97.535185           1     0.944426        1.0   \n",
       "67   49.072563   51.883212           0     0.010071        0.0   \n",
       "68   80.279574   92.116061           1     0.999952        1.0   \n",
       "69   66.746719   60.991394           1     0.709301        1.0   \n",
       "70   32.722833   43.307173           0     0.000062        0.0   \n",
       "71   64.039320   78.031688           1     0.977396        1.0   \n",
       "72   72.346494   96.227593           1     0.999893        1.0   \n",
       "73   60.457886   73.094998           1     0.884276        1.0   \n",
       "74   58.840956   75.858448           1     0.905241        1.0   \n",
       "75   99.827858   72.369252           1     0.999955        1.0   \n",
       "76   47.264269   88.475865           1     0.917695        1.0   \n",
       "77   50.458160   75.809860           1     0.626744        1.0   \n",
       "78   60.455556   42.508409           0     0.015840        0.0   \n",
       "79   82.226662   42.719879           0     0.599469        1.0   \n",
       "80   88.913896   69.803789           1     0.999282        1.0   \n",
       "81   94.834507   45.694307           1     0.973472        1.0   \n",
       "82   67.319257   66.589353           1     0.894532        1.0   \n",
       "83   57.238706   59.514282           1     0.203193        0.0   \n",
       "84   80.366756   90.960148           1     0.999941        1.0   \n",
       "85   68.468522   85.594307           1     0.997982        1.0   \n",
       "86   42.075455   78.844786           0     0.354560        0.0   \n",
       "87   75.477702   90.424539           1     0.999820        1.0   \n",
       "88   78.635424   96.647427           1     0.999973        1.0   \n",
       "89   52.348004   60.769505           0     0.106959        0.0   \n",
       "90   94.094331   77.159105           1     0.999944        1.0   \n",
       "91   90.448551   87.508792           1     0.999985        1.0   \n",
       "92   55.482161   35.570703           0     0.001424        0.0   \n",
       "93   74.492692   84.845137           1     0.999322        1.0   \n",
       "94   89.845807   45.358284           1     0.924570        1.0   \n",
       "95   83.489163   48.380286           1     0.858639        1.0   \n",
       "96   42.261701   87.103851           1     0.750882        1.0   \n",
       "97   99.315009   68.775409           1     0.999897        1.0   \n",
       "98   55.340018   64.931938           1     0.339275        0.0   \n",
       "99   74.775893   89.529813           1     0.999751        1.0   \n",
       "\n",
       "   GoodorBadPrediction  \n",
       "0      good-prediction  \n",
       "1      good-prediction  \n",
       "2      good-prediction  \n",
       "3      good-prediction  \n",
       "4      good-prediction  \n",
       "5      good-prediction  \n",
       "6      good-prediction  \n",
       "7       bad-prediction  \n",
       "8      good-prediction  \n",
       "9      good-prediction  \n",
       "10      bad-prediction  \n",
       "11     good-prediction  \n",
       "12     good-prediction  \n",
       "13     good-prediction  \n",
       "14     good-prediction  \n",
       "15     good-prediction  \n",
       "16      bad-prediction  \n",
       "17     good-prediction  \n",
       "18     good-prediction  \n",
       "19     good-prediction  \n",
       "20     good-prediction  \n",
       "21     good-prediction  \n",
       "22     good-prediction  \n",
       "23     good-prediction  \n",
       "24     good-prediction  \n",
       "25     good-prediction  \n",
       "26     good-prediction  \n",
       "27      bad-prediction  \n",
       "28     good-prediction  \n",
       "29     good-prediction  \n",
       "30     good-prediction  \n",
       "31     good-prediction  \n",
       "32     good-prediction  \n",
       "33      bad-prediction  \n",
       "34     good-prediction  \n",
       "35     good-prediction  \n",
       "36      bad-prediction  \n",
       "37     good-prediction  \n",
       "38     good-prediction  \n",
       "39     good-prediction  \n",
       "40     good-prediction  \n",
       "41     good-prediction  \n",
       "42     good-prediction  \n",
       "43      bad-prediction  \n",
       "44     good-prediction  \n",
       "45     good-prediction  \n",
       "46     good-prediction  \n",
       "47     good-prediction  \n",
       "48     good-prediction  \n",
       "49     good-prediction  \n",
       "50     good-prediction  \n",
       "51     good-prediction  \n",
       "52     good-prediction  \n",
       "53     good-prediction  \n",
       "54     good-prediction  \n",
       "55     good-prediction  \n",
       "56     good-prediction  \n",
       "57      bad-prediction  \n",
       "58     good-prediction  \n",
       "59     good-prediction  \n",
       "60     good-prediction  \n",
       "61     good-prediction  \n",
       "62     good-prediction  \n",
       "63     good-prediction  \n",
       "64     good-prediction  \n",
       "65     good-prediction  \n",
       "66     good-prediction  \n",
       "67     good-prediction  \n",
       "68     good-prediction  \n",
       "69     good-prediction  \n",
       "70     good-prediction  \n",
       "71     good-prediction  \n",
       "72     good-prediction  \n",
       "73     good-prediction  \n",
       "74     good-prediction  \n",
       "75     good-prediction  \n",
       "76     good-prediction  \n",
       "77     good-prediction  \n",
       "78     good-prediction  \n",
       "79      bad-prediction  \n",
       "80     good-prediction  \n",
       "81     good-prediction  \n",
       "82     good-prediction  \n",
       "83      bad-prediction  \n",
       "84     good-prediction  \n",
       "85     good-prediction  \n",
       "86     good-prediction  \n",
       "87     good-prediction  \n",
       "88     good-prediction  \n",
       "89     good-prediction  \n",
       "90     good-prediction  \n",
       "91     good-prediction  \n",
       "92     good-prediction  \n",
       "93     good-prediction  \n",
       "94     good-prediction  \n",
       "95     good-prediction  \n",
       "96     good-prediction  \n",
       "97     good-prediction  \n",
       "98      bad-prediction  \n",
       "99     good-prediction  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"probability\"] = sigmoid(z(x, theta))\n",
    "df.loc[df['probability'] >= .5  , 'ZeroOROne'] = 1\n",
    "df.loc[df['probability']  < .5  , 'ZeroOROne'] = 0\n",
    "df.loc[df['AdmitORNot'] == df['ZeroOROne']   , \"GoodorBadPrediction\"    ] = \"good-prediction\"\n",
    "df.loc[df['AdmitORNot'] != df['ZeroOROne']   , \"GoodorBadPrediction\"    ] = \"bad-prediction\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
